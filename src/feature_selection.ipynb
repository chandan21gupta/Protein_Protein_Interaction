{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function generates the training and testing dataset to be used for training and testing purposes with various models respectively. \n",
    "'''\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_train_test_data(split = 0.3, random_state = 42, scaling = 'standard', sampling = True, show_plots = True):\n",
    "\n",
    "\t'''\n",
    "\tThis method generates the training and test data. \n",
    "\tParameters :- split : Float, (0,1) - fraction of size of testing data to be used to test the model.\n",
    "\t\t\t\t  random_state : Integer - state of the randomization of the sampling data.\n",
    "\t\t\t\t  scaling : String, 'normal_negative', 'normal_positive', 'standard' - Type of scaling to be used, scaling data by \n",
    "\t\t\t\t  \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t[-1,1], [0,1], Standard Normal respectively\n",
    "\t\t\t\t  sampling : Boolean - To generate synthetic data using training data with SMOTE\n",
    "\t\t\t\t  show_plots : Boolean - To show target variable distribution after each sampling method.\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t'''\n",
    "\n",
    "\tdata = pd.read_csv('../extracted_datasets/raw.csv', index_col = [0])\n",
    "\n",
    "\tX = data[data.columns[0:100]]\n",
    "\n",
    "\ty = data['y']\n",
    "    \n",
    "\tif show_plots == True:\n",
    "\t\tsns.countplot(y).set_title('Target Distribution in whole dataset')\n",
    "\t\tplt.show()\n",
    "\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = random_state, stratify = y, test_size = split)\n",
    "\n",
    "\n",
    "\tif scaling == 'normal_negative':\n",
    "\t\tscale = MinMaxScaler(feature_range = (-1,1))\n",
    "\n",
    "\telif scaling == 'normal_positive':\n",
    "\t\tscale = MinMaxScaler()\n",
    "\n",
    "\telif scaling == 'standard':\n",
    "\t\tscale = StandardScaler()\n",
    "\n",
    "\tif sampling == False:\n",
    "\n",
    "\t\tX_train = scale.fit_transform(X_train)\n",
    "\t\tX_test = scale.transform(X_test)\n",
    "\n",
    "\t\tif show_plots == True:\n",
    "\t\t\tsns.countplot(x = y_train).set_title('Target Distribution in Training Dataset')\n",
    "\t\t\tplt.show()\n",
    "\t\t\tsns.countplot(x = y_test).set_title('Target Distribution in Test dataset')\n",
    "\t\t\tplt.show()\n",
    "\n",
    "\t\treturn X_train, X_test, y_train, y_test\n",
    "\n",
    "\telse:\n",
    "\n",
    "\t\tif show_plots == True:\n",
    "\t\t\tsns.countplot(x = y_train).set_title('Target Distribution in Training Dataset without SMOTE')\n",
    "\t\t\tplt.show()\n",
    "\n",
    "\t\toversample = SMOTE()\n",
    "\t\tX_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "\t\tX_train = scale.fit_transform(X_train)\n",
    "\t\tX_test = scale.transform(X_test)\n",
    "\n",
    "\t\tif show_plots == True:\n",
    "\t\t\tsns.countplot(x = y_train).set_title('Target Distribution in Training Dataset with SMOTE')\n",
    "\t\t\tplt.show()\n",
    "\t\t\tsns.countplot(x = y_test).set_title('Target Distribution in Test dataset')\n",
    "\t\t\tplt.show()\n",
    "\t\treturn X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = generate_train_test_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X_train)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(X_train)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
    "X_test_df = pd.DataFrame(data = y_train, columns = ['y'])\n",
    "print(X_test_df)\n",
    "finalDf = pd.concat([principalDf, X_test_df], axis = 1)\n",
    "finalDf\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = [0,1]\n",
    "colors = ['r', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['y'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = generate_train_test_data(sampling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X_train)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(X_train)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
    "X_test_df = pd.DataFrame(data = y_train, columns = ['y'])\n",
    "finalDf = pd.concat([principalDf, X_test_df], axis = 1)\n",
    "finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = [0,1]\n",
    "colors = ['r', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['y'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = generate_train_test_data(sampling = True, show_plots = False, scaling = 'standard')\n",
    "tsne_em = TSNE(n_components=2, perplexity=20.0, n_iter=1000, verbose=1).fit_transform(X_train)\n",
    "from bioinfokit.visuz import cluster\n",
    "color_class = y_train.to_numpy()\n",
    "cluster.tsneplot(score=tsne_em, colorlist=color_class, legendpos='upper right', legendanchor=(1.15, 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
